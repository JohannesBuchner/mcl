
\import{aephea/simpledocument.zmm}

\def{abc}{\sc{ABC}}
\def{MCL}{\sc{MCL}}
\def{mcl}{\bf{mcl}}

\begin{simpledocument}{
   {html_title}{MCL - an algorithm for clustering graphs}
   {title}{}
   {author}{Stijn van Dongen}
   {toc_and_date}{0}
   {css_import}{{../style.css}}
   {css_append}{
      body { font-family: "Garamond", "Gill Sans", "Verdana", sans-serif; }
      td.sheep {
         background-color: #dddddd;
      }
      td.leader {
         background-color: #eeeeee;
         text-align: center;
         font-style: italic;
      }
      h1 {
        text-align: center;
      }
      h3 {
        text-align: left;
      }
      table#index { border-collapse: collapse }
      table#index tr:first-child { border-top: none }
      table#index tr { border-top: 1px solid darkred }

      .release { font-family: monospace; }
   }
   {year}{0}
   {month}{abc}
   {day}{mon}
   {keywords}{cluster algorithm for graphs, clustering algorithm, graph clustering, cluster analysis software, community structure in networks}
   {head_append}{
      \<*link rel="shortcut icon" type="image/x-icon" href="../favicon.ico">
   }
}

\<table
   id=index
   width=100%
   style="margin-top:1em"
   cellspacing=0
   cellpadding=10
   summary="index and links"
>
\<tr>{
   \<td class=leader>{software}
   \<td class=sheep>{\iref{source}{download}}
   \<td class=sheep>{\iref{util}{Network analysis}}
   \<td class=sheep>{\iref{pkg}{packages}}
   \<td class=sheep>{\iref{impl}{C, R, java, perl}}
   \<td class=sheep>{\lref{man/clmprotocols.html}{Protocols}}
}

\<tr>{
   \<td class=leader>{documentation}
   \<td class=sheep>{\lref{man/mcl.html}{program manual}}
   \<td class=sheep>{\lref{man/mclfaq.html}{FAQ}}
   \<td class=sheep>{\lref{man/distindex.html}{other manuals}}
   \<td class=sheep>{\iref{news}{NEWS}}
   \<td class=sheep>{\iref{questions}{Questions}}
}

\<tr>{
   \<td class=leader>{writings}
   \<td class=sheep>{\lref{lit/index.html}{publications, citations}}
   \<td class=sheep>{\lref{intro.html}{introduction I}}
   \<td class=sheep>{\lref{intro2.html}{introduction II}}
   \<td colspan=2 class=sheep>{}
}

\""{
   \<td class=leader>{visualization}
   \<td class=sheep>{\lref{ani/mcl-animation.html}{animation}}
   \<td class=sheep>{\iref{biolayout}{BioLayout}}
   \<td colspan=3 class=sheep>{}
}

\</table>


\<h1 style="margin-top:2em">{MCL - a cluster algorithm for graphs}

\<div style="text-align:center; margin-top:1em">{
   \<*img src=img/fa_header_800_200.png alt="Four iterands of MCL visualized">
}


\: <h3>{A short introduction}

\par{
   The \bf{\MCL algorithm} is short for the
   \bf{Markov Cluster Algorithm}, a fast and scalable unsupervised cluster algorithm
   for graphs based on simulation of (stochastic) flow in graphs.
   The algorithm was invented/\aref{mcl-discovery.html}{discovered} by Stijn van Dongen
(that is, \aref{http://micans.org/stijn/}{me})
   at the
\aref{http://www.cwi.nl}{Centre for Mathematics and Computer Science}
   (also known as CWI) in the Netherlands.  The PhD thesis
\lref{lit/index.html}{\it{Graph clustering by flow simulation}}
   is centered around this algorithm,
   the main topics being the mathematical theory behind it, its position
   in cluster analysis and graph clustering, issues concerning
   scalability, implementation, and benchmarking, and performance
   criteria for graph clustering in general.
   The work for this thesis was carried out under supervision of
\aref{http://www.cwi.nl/~jve/}{Jan van Eijck} and
\aref{http://www.cwi.nl/~mich/}{Michiel Hazewinkel}.
   The thesis, technical reports, and preprints can be found in
\lref{lit/index.html}{the reading section}.

   For quickly getting an idea of how \MCL operates, consider
   the flow pictorial at the top of this page,
   or even better, have a look at an
\lref{ani/mcl-animation.html}{animation} of the \MCL process.

   }


\<h3>{A cluster algorithm for graphs, a community detection algorithm for networks}
\par{
   A \it{cluster algorithm for graphs} means exactly the same as a \it{community detection
   algorithm for networks}. This is a severe and unfortunate case of divergent terminology.
   My training as a mathematician has led me to use \it{graph} predominantly.
   This word has other meanings however, and is not always intuitive to people
   from other realms of science. Hence I have begun to appreciate and increasingly use
   \it{network}. On the other hand, the phrase \it{commnunity detection}
   seems a bit narrow and I strongly prefer the idioms \it{clustering} and \it{cluster analysis}.
   Throughout these pages and the \mcl documentation \it{graph} is used a lot,
   nowadays interspersed with usage of \it{network}. These should
   be understood to be entirely interchangeable \- not just on these pages, but
   in a very broad sense.
   Finally, \it{partition} means the same as \it{clustering}, that is, a separation
   into mutually disjoint subsets that cover the entire set of interest.
   The difference between these two terms is that \it{clustering}
   excludes the possibility of overlap by convention, so that it is still
   possible to speak of an \it{overlapping clustering}, whereas
   \it{partition} excludes the possibility of overlap by definition.
   }

\<h3>{Networks, clusterings, and matrices}
\par{
   A graph or network can be encoded as a sparse matrix, and the \MCL algorithm
   is most naturally phrased in terms of algebraic operations on matrices.
   Conveniently, a clustering can also be encoded as a matrix, with each
   cluster encoded as a (column) characteristic vector. The matrix row domain
   represents the nodes in the network and the columns represent the clusters.
   With this representation, the \it{confusion} or \it{contingency} matrix
   between two clusterings (counting the size of all pairwise cluster
   intersections between the two clusterings) is easily computed as a matrix
   product. Several other clustering manipulations can also be expressed using
   matrix compositions.

   Hence the \MCL documentation is full of references to matrices. Depending on
   context these encode either networks or clusterings.  On rare occassions a
   matrix may encode a mapping from one domain to another, for example to
   encode species annotation for genes or proteins. For users of \MCL
   software none of this need be of any concern however.

   }


\<h3>{Network analysis}
\par{
   The \MCL software includes \lref{man/mclfamily.html}{other programs} that
   implement various modes of network analysis. Networks may be constructed
   from array data using Pearson or Spearman correlations, and analysed at
   different edge weight thresholds. Clustering distances can be computed,
   clusterings at different levels of granularity reconciled into trees, and
   node indices reordered to show multiple levels of cluster structure within a
   linear ordering.  Multiple clusterings can be used to find volatile nodes
   that are peripheral in nature, as well as approximate clusters that are
   consistently found among a larger range of clusterings.  Applications exist
   to compute network centrality betweenness, clustering coefficients, and
   diameter, eccentricity, and shortest paths through networks.

   }



\<h3>{Applications, availability and protocols}

\enref{apps}{}
\par{
   \MCL has been applied in a number of different domains.
   Currently the number of papers citing core \MCL publications is
   well over five hundred.  Get a quick impression from Google Scholar

   for \aref{http://scholar.google.com/scholar?q=%22an+efficient+algorithm+for+large-scale+detection+of+protein+families%22}{the Enright/van Dongen/Ouzounis} paper
   or \aref{http://scholar.google.com/scholar?q=%22graph+clustering+by+flow+simulation%22}{my thesis}.
   Also of interest is the \aref{http://scholar.google.com/scholar?q=%22OrthoMCL+identification+of+ortholog+groups+for+eukaryotic+genomes}{OrthoMCL} paper.

   Other potential applications that come to mind are (computational) chemistry
   and multi-level approaches in graph partitioning (c.q. VLSI design).
   }

\par{
\iref{source}{My implementation of the \MCL algorithm}
   is available from this page for download.
\iref{util}{Several other programs} for manipulating
   graphs, matrices, and clusterings, come with it.
\lref{man/distindex.html}{Manual pages} in various formats are available.
   Short protocols for clustering from sequence similarities and
   from gene expression data are sketched out \lref{man/clmprotocols.html}{here}.

   }


\<h3>{Chararacteristics of MCL}

\par{
  The algorithm is very fast, very scalable, and has a number of
  attractive properties causing it to deliver high-quality clusterings.
  }

\def{myitem#1}{\item{\<span style="font-weight:bold; font-family:Garamond">{\1}}}

\begin{itemize}{
   {flow}{cascade}
   {interitem}{1}
   {itemmargin}{2}
   {textindent}{1}
   {type}{mark}
   {mark}{\*{itembullet}}
   {align}{right}
}
\myitem{simple}
\car{
   The algorithm simulates flow using (alternating) two simple
   algebraic operations on matrices. Its formulation is simple and
   elegant.  There are no high-level procedural instructions for
   assembling, joining, or splitting of groups - cluster structure
   is bootstrapped via a flow process that is inherently affected by
   any cluster structure present.}

\par{
   The first operation used is \bf{expansion}, which
   coincides with normal matrix multiplication. Expansion models the
   spreading out of flow, it becoming more homogeneous.  The second
   is \bf{inflation}, which is mathematically speaking a Hadamard
   power followed by a diagonal scaling.  Inflation models the
   contraction of flow, it becoming thicker in regions of higher
   current and thinner in regions of lower current.  The \MCL process
   causes flow to spread out within natural clusters and evaporate
   inbetween different clusters. This
   \lref{ani/mcl-animation.html}{animated example} of an \MCL process
   may give you an impression of its modus operandi.}

\myitem{adaptable}
\car{
   By varying a single parameter, clusterings on different scales
   of granularity can be found. The number of clusters can not and
   need not be specified in advance, but the algorithm can be adapted
   to different contexts.}

\myitem{emergent}
\car{
   The issue 'how many clusters?' is not dealt with
   in an arbitrary manner, but rather by strong internal logic.
   Cluster structure leaves its marks on the flow process simulated
   by the algorithm, and the flow parameters control the granularity
   of the cluster imprint.}

\myitem{scalable}
\car{
   The limit of the \MCL process (the process simulated
   by the algorithm) is in general extremely sparse, and the iterands
   are sparse in a weighted sense.  This gives the means to scale
   the algorithm drastically, leading to a worst-case
   complexity of order Nk^2,
   where N is the number of nodes of the input graph, and where k is
   a threshold for the number of resources allocated per node.  }

\myitem{intrinsic}
\car{
   The iterands of the \MCL process
   have structural properties which allow a cluster interpretation,
   and which generalize the mapping of limits onto clusterings.
   The mathematics associated with the process shows that there
   is an intrinsic relationship between the \MCL process and cluster
   structure in graphs.  This is very valuable given the many heuristic
   approaches in cluster analysis.}

\myitem{fast}
\car{
   An optimized \MCL implementation, such as found on this page, should have complexity \v{O(N k\<sup>{2})}, where \v{N} is the number
   of nodes in the graph, and \v{k} is the number of resources allocated per node. This number can be chosen
   surprisingly low without affecting clustering quality. The reason is that \MCL computes very much a localized
   process, and consequently it is possible to implement a pruning regime that takes advantage
   of this. Disappointingly, a number of publications claim that \MCL's complexity is \v{O(N\<sup>{3})}, however, this
   is only true if only an extremely naive implementation is considered.
   For more information please read the FAQ entries about \lref{man/mclfaq.html#resource}{resources} and
   \lref{man/mclfaq.html#howfast}{speed}.
}

\end{itemize}

\par{
   For a full description of the \MCL algorithm and process
   you are advised to read one of the technical reports in the
\lref{lit/index.html}{reading section}.
   It is also possible to view \lref{intro.html}{a somewhat longer introduction} or
   an introduction to some of the \lref{intro2.html}{mathematics associated}
   with \MCL.}


\par{
   The basic interface to the algorithm is very simple  - you need
   only one option (the \bf{-I} flag) to get to the heart of it,
   and for large graphs you should also be aware of the the \bf{-scheme}
   flag for regulating resources.  The default approach is to
   vary the argument to \bf{-I} over some interval (doing
   an mcl run for each value), and analyze the clustering
   output with the other programs that come with \MCL
(\lref{man/distindex.html}{cf the mcl manuals}).}


\enref{news}{}
\<h1>{News}


\def{dcar#2}{
   \<p class="default L49" style="margin-top:1em; margin-left:-2em; margin-bottom:0em;">{
      \<span style="margin:0em; font-weight:bold; font-family:Garamond;">{\1}
   }
   \<p class="default L50" style="margin-top:0.2em;">{
      \2
   }
}

\begin{itemize}{
   {flow}{cascade}
   {interitem}{1}
   {type}{mark}
   {mark}{\*{itembullet}}
   {align}{left}
}

\myitem{18 Sep 09}
\car{
   \span{release}{mcl-09-261} released. The previous release introduced a bug in the clustering
   interpretation code. If a clustering contained overlap (a rare
   event) mcl would, while splitting this overlap, separate all clusters not
   involved in overlap into singletons. The bug, now fixed, was
   reported by Tao Yue. The default action for mcl is to remove overlap;
   use \v{-overlap keep} to keep it.
   }

\myitem{23 Apr 09}
\car{
   Affinity propagation clustering and the Markov Cluster algorithm have finally been
   compared, in \aref{http://www.biomedcentral.com/1471-2105/10/99}{Markov
   clustering versus affinity propagation for the partitioning of protein interaction graphs},
   an article by Jim Vlasblom and Shosana Wodak in BMC Bioinformatics.
   }

\par{
   As this is a first comparison it should not be taken as a final verdict, and it
   must be considered that different algorithms may have different strengths and
   weaknesses and different areas of applicability. That said, the results from the
   above paper favour \MCL.
   }

\<blockquote>{
   Our analysis shows that the \MCL procedure is significantly more tolerant to
   noise and behaves more robustly than the AP algorithm. The advantage of \MCL
   over AP is dramatic for unweighted protein interaction graphs, as AP displays
   severe convergence problems on the majority of the unweighted graph versions
   that we tested, whereas \MCL continues to identify meaningful clusters, albeit
   fewer of them, as the level of noise in the graph increases. \MCL thus remains
   the method of choice for identifying protein complexes from binary interaction
   networks.}

\par{
   Incidentally, there is a long list of papers in which clustering methods are
   proposed and validated (and shown to be superior) by comparing with, among
   others, \MCL. In many cases I have doubts about the comparison methodology
   that was used, but the list is simply too long to attempt analaysis.  I
   will, however, gladly list and analyse any comparison performed by
   independent researchers, whatever the conclusion may be.
   }


\myitem{07 Nov 08}
\car{
   \bf{mcxdeblast} in the \span{release}{08-157} release contains a bug, and a
   \lref{src}{new \span{release}{08-312} release}
   has been made.  It will probably be followed up by a more
   thoroughly vetted release in the coming weeks.  You can also just download
   \lref{mcxdeblast}{a patched version of mcxdeblast}.
}

\myitem{05 Jun 08}
\car{
   \span{release}{mcl-08-157} released. From the Freshmeat announcement:}
\<blockquote>{
The mcl suite is moving towards a wider focus on general purpose large scale
graph analysis, with the emphasis, besides clustering, on basic graph and
clustering measures and transformations. The program mcxarray can now transform
tabular gene expression data into graph input. The utility clm computes
clustering coefficients, diameter and eccentricity, and betweenness centrality.
Many fixes and improvements were made throughout.}

\par{
   A longer list of changes is given in the \lref{src/ChangeLog}{ChangeLog}.

   }

\myitem{10 May 08}
\car{
   \MCL was used in the April 2008 Nature publication
   \aref{http://www.nature.com/nature/journal/v452/n7188/abs/nature06614.html}{Broad phylogenomic sampling improves resolution of the animal tree of life},
   and this was subsequentely
   \aref{http://www.ams.org/mathmedia/archive/05-2008-media.html#two}{reported by the AMS math in the media column}.

   }


\myitem{19 March 08}
\car{
   Ravi Tharakan first ran into trouble, then solved the issues, when
   installing \MCL on Cygwin under Windows Vista.
   One issue is to
   \it{set the 'Default
   text type' option to 'DOS/ text' instead of 'Unix / binary' when you
   install cygwin \- then everything works fine, and you don't need to use
   d2u} (the latter, d2u, is a utility to convert DOS line endings
   to Unix line endings).
   Another is to make sure that the Cygwin dll can be found via
   the PATH variable. If necessary, augment the PATH variable
   to include the path where cygwin1.dll can be found.
}


\myitem{20 February 08}
\car{
   My article
   \aref{http://link.aip.org/link/?SJMAEL/30/121/1}{
   Graph Clustering Via a Discrete Uncoupling Process}
   was published (SIAM Journal on Matrix Analysis and Applications,
   Volume 30 Issue 1, pp. 121-141).
   It largely corresponds with the second technical report referenced below,
   except that it contains less material and benefited from many useful
   reviewer comments.
   Why was it published sooo long after my PhD thesis was published?
   The answer is a story of persistance and abandonment, alternating, repeatedly.
}

\myitem{2 March 07}
\car{
   In Science the following clustering method was published:
   \it{Clustering by Passing Messages Between Data Points,
   Brendan J. Frey and Delbert Dueck,
   Science 16 February 2007,
   Vol. 315. no. 5814, pp. 972 - 976}.
   The authors make a number of strong claims, including

   }

\begin{spacing}{{left}{10}}
\par{
   .. Affinity propagation found clusters with much lower error than
   other methods, and it did so in less than one hundredth the amount
   of time.
   }
\end{spacing}


\par{
   However, in their paper they mainly compare with the k-centers algorithm,
   which seems scant evidence to support this claim.  Interestingly there are
   very clear conceptual similarities between APC (affinity propagation
   clustering) and \MCL as detailed below.
   It will be interesting to see how APC and \MCL compare, preferably
   by unbiased people (unlike myself) similar as in
   \iref{13nov06}{this paper comparing cluster methods}.
   }


\par{
   Their work starts from a message passing paradigm (the sum product
   algorithm) that generalizes
   a number of other algorithms, such as the Viterbi algorithm, Pearl's
   belief propagation algorithm, the iterative turbo decoding algorithm,
   and certain fast Fourier transform algorithms.
   The APC algorithm is different in that it incorporates loops,
   which makes it somewhat less amenable to a formal and rigorous analysis.
   Interestingly, just from the formulation of the algorithm, it possesses
   strong similarities to \MCL.
   Its \it{responsibility} and \it{availability} update rules
   seem to represent reinforcement and recombination updates similar
   to the operations of \it{inflation} and \it{expansion} in \MCL.
   In this respect both algorithms have a similar feel and can be classified
   as emergent algorithms.
   }

\par{
   When looking at a visualization of APC the resemblances with \MCL are
   quite striking as seen from this
   \lref{ani/mcl-animation.html}{\MCL animation}.
   It would be nice to see these two methods compared.
   }


\enref{13nov06}{}
\myitem{13 Nov 06}
\car{
   \aref{http://www.biomedcentral.com/1471-2105/7/488/abstract}{\:/
\it{Evaluation of clustering algorithms for protein-protein interaction networks}},
   Sylvain Brohee and Jacques van Helden, BMC Bioinformatics 2006, 7:488.  This
   paper contains a four-way comparison of Markov Clustering (\MCL), Restricted
   Neighborhood Search Clustering (RNSC), Super Paramagnetic Clustering (SPC),
   and Molecular Complex Detection (MCODE).  Among the conclusions are that \MCL
   is robust to graph alterations and that it performs favourably at the task
   of extraction of complexes from interaction networks.}


\myitem{12 Sep 06}
\car{
   In the last Ensembl protein families analysis mcl was run on a graph built on
   1008387 nodes (proteins).  The process took a combined CPU time of 23 hours
   on 8 processors and ran in 7 hours wall clock time. Reading the matrix from
   the 1.7G file probably took a substantial amount of time.}

\myitem{27 Feb 06}
\car{
   As of \span{release}{mcl-06-058} a very small perl mcl implementation called
   \lref{scripts/minimcl}{minimcl} is shipped with the mcl distribution.
   Analyze it and tinker with it to gain a better understanding of mcl.
   minimcl is fully functional but of course very slow.}

\myitem{11 Nov 05}
\car{
   As of \span{releases}{mcl-05-314} \bf{mcl} is able to read in label input
   directly and return the clustering in terms of those labels.
   A very small example is the file \v{cathat} below.}

\verbatim{---8<------8<------8<------8<------8<---
cat hat  0.2
hat bat  0.16
bat cat  1.0
bat bit  0.125
bit fit  0.25
fit hit  0.5
hit bit  0.16
--->8------>8------>8------>8------>8---}

\car{It can be clustered like this:}

\verbatim{mcl cathat --abc -o out.cathat}

\car{The file out.cathat should now like like this}

\verbatim{---8<------8<------8<------8<------8<---
cat hat bat
bit fit hit
--->8------>8------>8------>8------>8---}

\end{itemize}


\enref{questions}{}
\<h3>{Questions}

\par{
   If you have questions that
   \lref{man/mclfaq.html}{are not answered in the mcl FAQ}
   please subscribe to the mcl-users mailing list
   at \httpref{http://listserver.ebi.ac.uk/mailman/listinfo/mcl-users}.
   I may respond to queries sent to me in private, but as I get quite
   a few of these I prefer to have a public forum that is archived.
   By posting your question in a publicly accessible forum you are
   helping other people that may have similar enquiries.
}

\par{
   When seeking help regarding running or compiling mcl or one
   of the other network analysis programs, remember to describe the problem as
   clearly as possible. This includes (whether it concerns compiling mcl or
   running mcl programs) a full description of what you did (i.e. the command
   line statements), what you expected, and what happened (i.e. the screen
   output or a concise description or example of unexpected contents found in
   files).  Do try to make examples as small as possible. Do not paste or
   attach files but rather use excerpts that demonstrate the issue at hand.
   
   }

\par{
   The mailing list will also be used for announcements of
   releases, for bug reports, and for other mcl-related matters.
}
   
\enref{biolayout}{}
\<h3>{Clustering from within BioLayout}

\par{
   \aref{http://www.biolayout.org/}{BioLayout}
   is a powerful 3D graph visualization and analysis Java application, allowing
   interaction with large graphs in 3-dimensional layouts. It can handle graphs
   with up to and over 10,000 nodes, has many modes of operations and supports
   many graph queries and analysis modes.  BioLayout has a facility to cluster
   the graph using mcl.  The resulting cluster structure is interpreted as a
   native class attribute and displayed by assigning colours to (the nodes in)
   clusters.
}

\<h3>{Emergent algorithm}

\par{
   None of the publications referenced on this page uses the phrase
   \it{emergent algorithm} to describe \MCL. The criteria
   listed in the slim
\aref{http://en.wikipedia.org/wiki/Emergent_algorithm}{Wikipedia entry}
   do all apply to \MCL however.}

\begin{itemize}{
   {flow}{compact}
   {interitem}{0}
   {align}{right}
   {mark}{\*{itembullet}}
}
\item
\car{
   Achieves predictable global effects
   }
\item
\car{
   Does not require global visibility
   }
\item
\car{
   Does not assume any kind of centralized control
   }
\item
\car{
   Self-stabilizing
   }
\end{itemize}

\par{
   This connection does not suddenly further our understanding of the \MCL
   algorithm in new ways, but it is certainly more profound than a lazy buzzword
   flip. Emergent algorithms have a place in science, and the listed criteria
   are important characteristics of \MCL. The algorithm can be implemented in a
   distributed network, if applied to sparse graphs.  This is implied by the
   locality of the operations employed and embodies the second criterion.}

\par{
   An important characteristic of \MCL that is perhaps not common in the
   class of emergent algorithms is that it is fully deterministic and to
   some extent amenable to mathematical analysis.}

\enref{source}{}
\<h1>{Download}


\par{
\bf{If you use this software in writing scientific papers, or you use this
software in any other medium serving scientists or students} (e.g.
web-sites, CD-ROMs) include proper reference to mcl's home on
http://micans.org/mcl/ and its author, Stijn van Dongen.  Also include \bf{at
least one} of the following citations - note that copies of the corresponding
publications can be retrieved via the links given.}

\begin{itemize}{
   {flow}{compact}
   {interitem}{1}
   {type}{mark}
   {mark}{\*{itembullet}}
   {align}{right}
}
\item
\car{
   Stijn van Dongen, \it{Graph Clustering by Flow Simulation}.
   PhD thesis, University of Utrecht, May 2000.\|
[ \httpref{http://www.library.uu.nl/digiarchief/dip/diss/1895620/inhoud.htm} ].
}
\item
\car{
   Stijn van Dongen. \it{A cluster algorithm for graphs}.
   Technical Report INS-R0010, National Research Institute for Mathematics and
   Computer Science in the Netherlands, Amsterdam, May 2000.\|
[ \httpref{http://www.cwi.nl/ftp/CWIreports/INS/INS-R0010.ps.Z} ].
}

\item
\car{
   Stijn van Dongen. \it{A stochastic uncoupling process for graphs}.
   Technical Report INS-R0011, National Research Institute for Mathematics and
   Computer Science in the Netherlands, Amsterdam, May 2000.\|
[ \httpref{http://www.cwi.nl/ftp/CWIreports/INS/INS-R0011.ps.Z} ].
}

\item
\car{
   Stijn van Dongen. \it{Performance criteria for graph clustering and Markov
   cluster experiments}. Technical Report INS-R0012, National Research
   Institute for Mathematics and Computer Science in the Netherlands,
   Amsterdam, May 2000.\|
[ \httpref{http://www.cwi.nl/ftp/CWIreports/INS/INS-R0012.ps.Z} ].
}

\item
\car{
   Stijn van Dongen. \it{Graph clustering via a discrete uncoupling
   process}.
   \aref{http://link.aip.org/link/?SJMAEL/30/121/1}{Siam Journal on Matrix Analysis and Applications 30-1, p121-141, 2008}.
}

\end{itemize}


\par{For biological applications, it is appropriate to cite in addition
the following paper, in which the application of \MCL to biological
graphs was first proposed.}


\begin{itemize}{
   {flow}{compact}
   {interitem}{1}
   {type}{mark}
   {mark}{\*{itembullet}}
   {align}{right}
   {smallertext}{0}
}
\item
\car{
   Enright A.J., Van Dongen S., Ouzounis C.A.
   \it{An efficient algorithm for large-scale detection of protein families},
   \aref{http://nar.oxfordjournals.org/cgi/content/full/30/7/1575}{Nucleic Acids Research 30(7):1575-1584 (2002)}.
}
\end{itemize}


\par{
   \lref{src/}{Download a a ready-to-install tarball containing my GPL-ed \MCL implementation in C}.
   In case you wonder, GNU GPL stands for
\aref{http://www.gnu.org/licenses/gpl.txt}{GNU General Public License}.
   It implies that the source code is available, and you have
   the freedom to modify the code to your needs. If you pass parts or
   all of the code, compiled parts of the code,
   or a derived product on to others, you have to make the code
   available to them on the same conditions.
   For more information about GNU software and the GNU philosophy go
\aref{http://www.gnu.org/philosophy/free-sw.html}{hither}.}

\par{
   Manual pages in \it{html, troff, and ps}
   are part of the distribution (and can be automatically
   installed), and they are also
\lref{man/distindex.html}{available from this site}.
   Several other programs are part of the mcl distribution, they
   are described below.}

\par{
   Many thanks go to Joost van Baal who packages this mcl implementation
   for Debian and autofooled \MCL. This implies that the tarball pointed
   to above should install on virtually any UNIX flavour.}

\par{
   The software is provided on an 'as is' basis. The implementation is fast
   (one of the aims in its design), and is grounded on a lean sparse
   matrix/vector architecture.  It is command-line based and the source code
   documentation is also \it{lean and sparse}.}


\<h1>{Network analysis, packages and interfaces}

\enref{util}{}
\<h3>{Network analysis}

\car{
   \MCL is part of a workbench of network and clustering analysis tools.
   There is a \lref{man/mclfamily.html}{meta manual page} listing
   the different applications and their use.
   
   }

\""{

\par{
   Several programs are part of the \MCL distribution. The main utility,
   in a class of its own, is \bf{mcl} itself, the
   clustering algorithm. It's manual is
\lref{man/mcl.html}{here}.}

\par{
   A second set of programs implements various
   kinds of general purpose manipulation of matrices in \MCL format
   (most notably for multiplying, transposing, pruning, and normalizing).
   Currently this set contains
   \bf{mcxassemble},
   \bf{mcx},
   \bf{mcxsubs},
   and
   \bf{mcxmap}.}

\par{
\lref{man/mcxassemble.html}{mcxassemble}
   is a powerful preprocessor for generating matrices.
   It takes a very free input format containing co-occurrence scores, which are
   presumably derived by a parser which has as its main task to
   establish a mapping between labels and mcl (integer) identifiers.
   The parser thus need not concern itself with the issue of how to build a
   matrix. This is left to mcxassemble, which is parametrized to a great extent.}

\par{
\lref{man/mcx.html}{mcx}
   is an interpreter for a stack language
   that provides comprehensive access to the mcl librarires.
   The mcl algorithm itself is easily implemented in two or three
   lines of code in this language.}

\par{
\lref{man/mcxsubs.html}{mcxsubs}
   is an all-round extractor
   of submatrices induced by unions and complements of clusters and/or
   simple indices.  Useful for all kinds of things, like studying results you
   find surprising - \it{why did this index not go into this cluster?}
   - \it{why did these clusters (not) merge together?} or just gaining
   insight - \it{what edges exist between these two sets of nodes?}
   et cetera.  Indices in mcxsub output can be tagged with the index
   of the cluster that they are in. The subpart specification strings,
   which are supplied as command line arguments, are quite powerful.}

\par{
\lref{man/mcxmap.html}{mcxmap}
   is for relabeling network nodes or matrix indices.}

\par{
   The third set is for analyzing clustering output.  The
   programs herein are also very useful;}

\par{
\lref{man/clminfo.html}{clminfo}
   for measuring the efficiency and other characteristics
   of a clustering (e.g. how much edge mass does the clustering capture, how
   large is the cluster footprint).}

\par{
\lref{man/clmdist.html}{clmdist}
   for measuring
   the similarity between two different clusterings and for measuring whether
   one clustering is almost a subclustering of the other.}

\par{
\lref{man/clmmeet.html}{clmmeet}
   for computing
   \lref{bkg/terms.html#term:meet}{the intersection}
   of an arbitrary number
   of clusterings. The intersection is the largest clustering that is a
   subclustering of all the given clusterings, and it can be used to identify
   areas of the network that are the most active under parameter shifts.}

\par{
\lref{man/clmmate.html}{clmmate}
   for computing the best matches between two clusterings.
   For each cluster in the first clustering, it finds all matching
   clusters in the second clustering, and it can generate a list
   of best matching pairs.}

\par{
\lref{man/clmformat.html}{clmformat}
   for displaying cluster results in terms
   of descriptive labels (rather than the indices \MCL works with)
   and measuring how well nodes fit in the cluster
   they are in, what other clusters are relevant for that node,
   and how cohesive the clusters of a given clustering are.}

\par{
\lref{man/clmimac.html}{clmimac}
   for interpreting matrices as clusterings. The \MCL iterands
   allow a generic interpretation as clusterings. This is one of the
   theoretical results that strongly link the \MCL process to cluster structure
   in networks.}

\par{
\lref{man/clmresidue.html}{clmresidue}
   for extending a clustering of a subnetwork onto a
   clustering of the larger encompassing network (by a simple majority vote rule).}

""}

\enref{mods}{}
\<h3>{Modules in the mcl distribution}

\car{
   As of \span{release}{mcl-05-314} clustering from BLAST results has been made very
   easy by mcl's newly acquired ability to read in label-type input.
   Go \lref{man/clmprotocols.html}{here} for more information.
   }

\par{
   You are advised to no longer use the TribeMCL module, as it has
   been superseded by the approach above.
   For biological applications it is of course appropriate
   to cite the Enright/van Dongen/Ouzounis paper in addition
   to one of the early MCL publications, as indicated
   in the \iref{source}{download section}.}


\""{mcxdeblast --line-mode=abc --out=- xyz.blast}


\enref{pkg}{}
\<h3>{Packaged MCL}

\par{
\aref{http://packages.debian.org/unstable/math/mcl.html}{Debian mcl package}
created by
\aref{http://mdcc.cx/}{Joost van Baal}.
Kari Pahula backported \span{release}{mcl-06-021} to
\aref{http://packages.debian.org/table/math/mcl.html}{Debian stable}.}


\par{
\aref{http://www.openbsd.org/cgi-bin/cvsweb/ports/math/mcl/}{OpenBSD mcl package}
   created by \bf{Andreas K\@e{auml}h\@e{auml}ri}.
   (I am not sure if the given URL is the best available link, but openBSD people
   surely know their way around).}

\par{
   Dan Thomasset has created source and binary i386 RPMs for \span{release}{mcl-06-058}. Retrieve
 \aref{http://research.stowers-institute.org/dct/repo/RPM/i386/mcl-06.058-1.i386.rpm}{the i386 RPM}
 and the
   \aref{http://research.stowers-institute.org/dct/repo/SRPMS/mcl-06.058-1.src.rpm}{source RPM}
   from the Stowers Institute.
    You can also get the \lref{mcl-06-058.rpm.spec}{spec file} created by Dan.}

\def{"-"}{\@{&ndash;}}

\enref{impl}{}
\<h3>{C, R, java, perl}
\par{
   The implementation available from this page is written in C and aims for
   maximum speed and scalability. Is is threaded and can thus utilize
   multi-core machines. On such hardware it has clustered networks with millions
   of nodes within hours. The interface is exclusively command-line and accepts
   a very simple line-based streamable format. As such it is easily
   incorporated as a component into larger projects or toolsets.
   }
   
\""{
   The next release or the one after that
   will feature mcl as a C library call including an interface for building
   the input network. This should make the implementation available for
   use within Java with JINI.
   }

\par{
   Rob Gevers has written an \aref{http://www.rob-gevers.com/pmwiki.php/MclR/MclR}{R interface to mcl}.
   It requires you have installed the mcl software available from this page.
   }

\par{
   \lref{scripts/minimcl}{minimcl} is written in perl and solely exists for educational
   purposes.}

\par{
   Gregor Heinrich has written a
\aref{http://www.arbylon.net/projects/knowceans-mcl/knowceans-mcl-src-20060805.zip}{
   Java implementation}
   of mcl. The zip file includes a 50-line mcl implementation in matlab, useful
   as a testbed and proof of concept. Find documentation
\aref{http://www.arbylon.net/projects/knowceans-mcl/doc}{there}.
   }






\end{simpledocument}


\""{
\item
\ccar{8 May 07}{
   Two people now have reported segmentation faults
   that went away after recompiling \MCL with optimization turned \it{off}.
   One of those was on a Linux 2.4.21 kernel running an ia64 SMP system.
   Further investigation seemed to indicate that the fault does not necessarily
   lie with \MCL, and the status, origin, and ownership of this bug are unclear.
   }
}
